# Example MLP configuration
model:
  name: "simple_mlp"
  input_size: 784
  hidden_sizes: [512, 256, 128]
  num_classes: 10
  dropout: 0.2

data:
  name: "dummy_tabular"
  num_samples: 1000
  num_features: 784
  num_classes: 10
  train:
    num_samples: 800
    num_features: 784
    num_classes: 10
  validation:
    num_samples: 200
    num_features: 784
    num_classes: 10

training:
  num_epochs: 50
  batch_size: 64
  learning_rate: 0.001
  weight_decay: 1e-4
  optimizer: "adam"
  scheduler: "plateau"
  factor: 0.5
  patience: 5
  loss: "cross_entropy"
  gradient_clip: 1.0
  save_interval: 10
  eval_interval: 1
  log_interval: 10
  use_tensorboard: true

experiment:
  seed: 42
  output_dir: "./outputs/mlp_experiment"
  device: "auto"
